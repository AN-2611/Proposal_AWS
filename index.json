[{"uri":"https://lehoangthai.github.io/proposal/2-proposal/","title":"Proposal","tags":[],"description":"","content":"AWS APPLICATION LOAD BALANCER DEPLOYING ADVANCED FEATURES OF AWS APPLICATION LOAD BALANCER 1. Executive Summary The business requires a web platform capable of serving thousands of concurrent users, ensuring high security, performance, scalability, and reliability. The proposed solution uses the AWS Cloud with a modern 3-tier architecture, leveraging managed services.\nThis proposal presents an evaluation of a Private Architecture AWS system design intended for deploying a secure, flexible, and high-performance backend environment. The system operates within a VPC (Virtual Private Cloud), consisting of a public subnet containing a NAT Gateway and private subnets housing the EC2 instances responsible for App, API, and WebSocket services.\nThis architecture emphasizes network segregation, observability, cost optimization, while maintaining future scalability.\n2. Problem Statement Current Problem Traditional backend deployment models (on-premises) face significant limitations in terms of scalability, flexibility, and operational efficiency. In the old architecture, all servers, databases, and network components were deployed on physical infrastructure managed by the internal IT team. This leads to several issues:\nHigh investment and maintenance costs: Purchasing and maintaining servers, storage devices, and network infrastructure requires large initial capital expenditure and ongoing operational costs.\nDifficult to scale flexibly: When traffic surges, system expansion requires manual intervention, causing service disruption or leading to over-provisioning of resources.\nComplex and error-prone deployment: Configuration, version management, and deployment processes across multiple environments (dev, test, prod) are manual, time-consuming, and prone to errors.\nLow fault tolerance: Hardware failures or misconfigurations can bring down the entire backend, as mechanisms for redundancy and automatic recovery are difficult to implement on physical infrastructure.\nDifficult to monitor and troubleshoot: Traditional systems often lack integrated observability tools, making performance and security monitoring challenging.\nSecurity and compliance burden: Manually maintaining firewalls, applying patches, and protecting data consumes significant resources and poses potential risks.\nThese limitations result in slow development cycles, high operating costs, and a lack of the flexibility needed to meet the requirements of modern applications.\nSolution To overcome the limitations of the traditional backend deployment model (on-premises), this proposal introduces a cloud-native backend environment on the AWS platform.\nThe solution leverages AWS serverless and managed services to achieve high scalability, robust security, optimized cost, and minimal operational complexity.\nBenefits and Return on Investment (ROI)\nEnhanced scalability and availability: Managed AWS services allow for near-limitless scaling without manual intervention, and the Multi-AZ design ensures fault tolerance and minimizes service downtime.\nSecurity and compliance: Implementing IAM, Security Groups, and data encryption protects the entire backend system. AWS complies with numerous international standards (ISO, SOC, GDPR\u0026hellip;), facilitating the company\u0026rsquo;s security certification process.\nCost Efficiency: Reduced initial investment costs, optimized operational expenditure, and automatic scaling adjusts resources according to the load, preventing waste from over-provisioning.\nBetter observability and monitoring: Using CloudWatch for monitoring, early fault detection, and rapid troubleshooting.\nFlexibility: The architecture is adaptable for future expansion into microservices or containers.\n3. Solution Architecture Main Flow: User → DNS (Route 53) → ALB. ALB (HTTPS termination using ACM) → distributes load to Web/API/WebSocket instances in private subnets. Instances run in Auto Scaling Groups across AZs, health-checked by ALB.\nOutbound traffic (updates, API calls) goes through NAT Gateway.\nLogs from ALB → S3, metrics from EC2/ALB → CloudWatch.\nCloudWatch alarms → SNS → notify Ops team. AWS Services Used\nVPC (Virtual Private Cloud): Creates a private network environment for the entire backend system. Subnets (Public \u0026amp; Private): Separates public resources (NAT) from private resources (App, API, WebSocket). NAT Gateway: Allows backend instances in the private subnet to securely access the Internet without exposing their IP addresses. EC2 Instances (App, API, WebSocket): Hosts and runs core backend services such as business logic, REST APIs, and real-time WebSocket connections. Application Load Balancer (ALB): Balances load across backend instances, ensuring availability and stable performance. Auto Scaling Group: Automatically scales the number of EC2 instances up or down based on system load. Amazon CloudWatch: Monitors performance, collects logs, and sends alerts upon incidents. Amazon SNS: Automatically sends notifications upon detection of critical events or system failures. Security Groups: Controls inbound/outbound network traffic to protect backend resources. Component Design\nThe backend system consists of three main layers:\nNetwork Layer The VPC is divided into Public and Private subnets. The Public subnet only contains the NAT Gateway, allowing the backend to access the Internet for updates or external API calls. The Private subnet contains the App, API, and WebSocket services, ensuring they are not directly accessible from the outside. Application Layer App Service: Handles core business logic, interacting with internal APIs. API Service: Receives and processes requests from the frontend or other systems via the Application Load Balancer (ALB). WebSocket Service: Provides real-time, bidirectional communication. ALB: Balances load across instances, reducing downtime and increasing reliability. Monitoring \u0026amp; Management Layer CloudWatch: Monitors logs and system performance, sends automatic alerts. SNS: Notifies the admin team of critical errors. Auto Scaling: Automatically scales EC2 resources up or down to optimize cost and performance. 4. Technical Deployment Deployment Phases\nResearch and Architecture Design: Research and design the AWS architecture. Cost Estimation and Feasibility Check: Use the AWS Pricing Calculator for estimation and adjustment. Architecture Refinement for Cost/Solution Optimization: Fine-tuning to ensure efficiency. Development, Testing, Deployment: System implementation. Technical Requirements\nSystem deployment will be layered: Network layer -\u0026gt; Security layer -\u0026gt; Compute \u0026amp; Application layer -\u0026gt; Scalability \u0026amp; Availability layer -\u0026gt; Storage \u0026amp; Data layer -\u0026gt; Monitoring \u0026amp; Logging layer. 5. Roadmap \u0026amp; Deployment Milestones Internship Period (Months 1-3): 3 months. Month 1: Research, learn to use AWS services. Month 2: Research, design, cost estimation, architectural refinement. Month 3: Implementation, testing, launch. 6. Budget Estimation The cost can be viewed on the AWS Pricing Calculator Or download the budget estimation file.\nInfrastructure Costs\nAWS Lambda: 0.00 USD/month (1,000 requests, 512 MB storage). S3 Standard: 0.15 USD/month (6 GB, 2,100 requests, 1 GB scan). Data Transfer: 0.02 USD/month (1 GB in, 1 GB out). AWS Amplify: 0.35 USD/month (256 MB, 500 ms request). Amazon API Gateway: 0.01 USD/month (2,000 requests). AWS Glue ETL Jobs: 0.02 USD/month (2 DPU). AWS Glue Crawlers: 0.07 USD/month (1 crawler). MQTT (IoT Core): 0.08 USD/month (5 devices, 45,000 messages). Total: 0.7 USD/month, 8.40 USD/12 months\nHardware: 265 USD one-time (Raspberry Pi 5 and sensors). 7. Risk Assessment Risk Matrix\nLog growth too fast: Medium impact, Medium probability. Exceeding budget: Medium impact, Low probability. Mitigation Strategy\nLog/Data growth: Archive old logs to S3 Glacier. Cost: AWS budget alerts, service optimization. Contingency Plan\nCost threshold exceeded → Trigger AWS Budgets alarm, scale down non-prod resources. Logs full → Transfer logs to Glacier or automatically delete old logs. 8. Expected Outcomes Downtime: Reduced thanks to HA, multi-AZ, ALB health check. Cost: Cost optimization of 20–30% thanks to auto scaling + logs lifecycle.\n"},{"uri":"https://lehoangthai.github.io/proposal/","title":"Internship Report","tags":[],"description":"","content":""},{"uri":"https://lehoangthai.github.io/proposal/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://lehoangthai.github.io/proposal/tags/","title":"Tags","tags":[],"description":"","content":""}]